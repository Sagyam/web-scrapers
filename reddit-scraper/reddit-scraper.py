# -*- coding: utf-8 -*-
"""scraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bVRqY2uPJGdZCKmkmMEUM6MAUEYnYxB9
"""

! pip install praw

# from google.colab import drive
# drive.mount('/content/drive')

import praw
import pandas as pd
from praw.models import MoreComments
import requests
import os
import re
from skimage import io

reddit = praw.Reddit(client_id="YDoGtLFypdYKtQ",
                     client_secret="m3OlNf-KmTOEZLCc3L8De7kEC0c",
                     password="r2)]a$%sJm2,9Bx",
                     user_agent="Sagyam",
                     username="rajanghimire534")

PWD = "/content/Data"
SUBREDDIT_NAME = 'roastme'
NO_OF_POSTS = 1
NO_OF_TOP_LEVEL_COMMENTS = 10
MIN_COMMENT_LENGTH = 10
MAX_COMMENT_LENGTH = 150
comments = []

def get_image(image_url, post_id):
    img_name = post_id + ".jpg"
    img_data = requests.get(image_url).content
    with open(img_name, 'wb') as handler:
      handler.write(img_data)
    if (verify_image(img_name)):
      return True
    else: return False

def verify_image(img_file):
    try:
        img = io.imread(img_file)
    except:
        return False
    return True

def get_comments(post_id):
    count = 1  
    index = 1                                     #skip first(MOD) comment 
    submission = reddit.submission(id = post_id)
    submission.comments.replace_more(limit=0)     #fetch only top level comment(limit=0)
    while count <= NO_OF_TOP_LEVEL_COMMENTS:
      comment = submission.comments[index].body  
      comment = cleanup(comment)
      if is_valid_length(comment) and is_good_comment(comment):
        count += 1
        yield comment
      index += 1

def cleanup(comment):
  comment = re.split('EDIT:', comment, flags=re.I)[0]
  comment = comment.replace('\r', '').replace('\n', '')
  comment = comment.replace('\'', '')
  comment = comment.lower()
  comment = re.sub('\W+',' ', comment)
  return comment

def is_valid_length(comment):
  #NOT WORKING
  if (len(comment) >= MIN_COMMENT_LENGTH) and (len(comment) <= MAX_COMMENT_LENGTH):
    print(len(comment))
    return True
  else: return False

def is_good_comment(comment):
  #NOT WORKING
  if (comment == 'removed') or (comment == 'deleted'):
    return False
  else:
    print(comment) 
    return True


def write_file(filename, comments):
    count = 0
    f = open("data.txt", "a", encoding= "utf-8")
    for comment in comments:
        count += 1
        prefix = filename + "#" + str(count) + "    "
        line = prefix + comment + '\n'
        f.write(line)
    f.close()

progress = 1
bad_post = 0
os.chdir(PWD) 
subreddit = reddit.subreddit(SUBREDDIT_NAME)

for post in subreddit.top(limit=NO_OF_POSTS):
    status = get_image(post.url, post.id)
    image_name = post.id + '.jpg'
    if (status):
      #Getting comments from yeild requires for loop
      for comment in get_comments(post.id):
        comments.append(comment)
      write_file(image_name, comments)
      print("Processed " + str(progress) + " posts")
    else:
      print(image_name + " was Corrupt")
      bad_post += 1
      print(str(progress-bad_post) + ' Good Post')

    progress += 1
    comments = []