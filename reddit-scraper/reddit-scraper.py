# -*- coding: utf-8 -*-
"""scraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bVRqY2uPJGdZCKmkmMEUM6MAUEYnYxB9
"""

! pip install praw

# from google.colab import drive
# drive.mount('/content/drive')

import praw
import pandas as pd
from praw.models import MoreComments
import requests
import os
import re
from skimage import io

reddit = praw.Reddit(client_id="",
                     client_secret="",
                     password="",
                     user_agent="",
                     username="")

PWD = "/content/Data"
SUBREDDIT_NAME = 'roastme'
NO_OF_POSTS = 1
NO_OF_TOP_LEVEL_COMMENTS = 10
MIN_COMMENT_LENGTH = 10
MAX_COMMENT_LENGTH = 150
comments = []

def get_image(image_url, post_id):
    img_name = post_id + ".jpg"
    img_data = requests.get(image_url).content
    with open(img_name, 'wb') as handler:
      handler.write(img_data)
    return bool((verify_image(img_name)))

def verify_image(img_file):
    try:
        img = io.imread(img_file)
    except:
        return False
    return True

def get_comments(post_id):
    count = 1  
    index = 1                                     #skip first(MOD) comment 
    submission = reddit.submission(id = post_id)
    submission.comments.replace_more(limit=0)     #fetch only top level comment(limit=0)
    while count <= NO_OF_TOP_LEVEL_COMMENTS:
      comment = submission.comments[index].body  
      comment = cleanup(comment)
      if is_valid_length(comment) and is_good_comment(comment):
        count += 1
        yield comment
      index += 1

def cleanup(comment):
  comment = re.split('EDIT:', comment, flags=re.I)[0]
  comment = comment.replace('\r', '').replace('\n', '')
  comment = comment.replace('\'', '')
  comment = comment.lower()
  comment = re.sub('\W+',' ', comment)
  return comment

def is_valid_length(comment):
    if len(comment) < MIN_COMMENT_LENGTH or len(comment) > MAX_COMMENT_LENGTH:
        return False
    print(len(comment))
    return True

def is_good_comment(comment):
    if comment in ['removed', 'deleted']:
        return False
    print(comment)
    return True


def write_file(filename, comments):
    with open("data.txt", "a", encoding= "utf-8") as f:
        for count, comment in enumerate(comments, start=1):
            prefix = filename + "#" + str(count) + "    "
            line = prefix + comment + '\n'
            f.write(line)

bad_post = 0
os.chdir(PWD)
subreddit = reddit.subreddit(SUBREDDIT_NAME)

for progress, post in enumerate(subreddit.top(limit=NO_OF_POSTS), start=1):
    status = get_image(post.url, post.id)
    image_name = post.id + '.jpg'
    if (status):
      #Getting comments from yeild requires for loop
      for comment in get_comments(post.id):
        comments.append(comment)
      write_file(image_name, comments)
      print("Processed " + str(progress) + " posts")
    else:
      print(image_name + " was Corrupt")
      bad_post += 1
      print(str(progress-bad_post) + ' Good Post')

    comments = []
